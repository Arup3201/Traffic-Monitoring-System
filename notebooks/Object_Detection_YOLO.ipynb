{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arup3201/Traffic-Monitoring-System/blob/main/notebooks/Object_Detection_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC2CTvb0Er6I"
      },
      "source": [
        "# Object Detection using YOLO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Google Colab\n",
        "# Comment it if you are using local machine\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!git clone https://github.com/Arup3201/Traffic-Monitoring-System.git\n",
        "!mkdir /content/Traffic-Monitoring-System/.data\n",
        "!unzip -q /content/drive/MyDrive/Projects/smartflow-traffic-manager/data/annotations.zip -d /content/Traffic-Monitoring-System/.data\n",
        "!unzip -q /content/drive/MyDrive/Projects/smartflow-traffic-manager/data/images.zip -d /content/Traffic-Monitoring-System/.data\n",
        "%cd Traffic-Monitoring-System/"
      ],
      "metadata": {
        "id": "M68PY91Uv41v",
        "outputId": "68345d2c-f6cb-49df-f7b9-607124c0afa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'Traffic-Monitoring-System'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 34 (delta 10), reused 11 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (34/34), 21.16 KiB | 7.05 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n",
            "/content/Traffic-Monitoring-System\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L_ep0NWOEpZB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jXAHlviaog2F"
      },
      "outputs": [],
      "source": [
        "S = 7\n",
        "B = 2\n",
        "C = 5\n",
        "BATCH_SIZE = 4\n",
        "IMG_SIZE = (448, 448)\n",
        "DATA_DIR = '.data'\n",
        "TRAIN_ANNOTATIONS = '.data/json_annotations/train_annotations.json'\n",
        "VAL_ANNOTATIONS = '.data/json_annotations/val_annotations.json'\n",
        "MODEL_DIR = 'model'\n",
        "MODEL_WEIGHTS = 'yolov1.h5'\n",
        "EPOCHS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kfx6MUgPog2F"
      },
      "outputs": [],
      "source": [
        "def read_json(filename):\n",
        "    json = joblib.load(filename)\n",
        "    return json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_rjOnqduog2G",
        "outputId": "e5620462-e646-4702-8382-52635e508cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image_path': 'bus/train/Elite-7-Large_jpg.rf.740cccbaac6544d3b0dd29e960cfc9ab.jpg',\n",
              " 'bbox': [[45, 135, 606, 588]],\n",
              " 'class': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_annotations = read_json(TRAIN_ANNOTATIONS)\n",
        "train_annotations[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DCQ4RMyaog2I",
        "outputId": "0825b625-b4a5-4f4e-901d-c7a19ca9d488",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image_path': 'bus/valid/Bus-7_jpg.rf.4322d53440e3c377c95a8b0761776609.jpg',\n",
              " 'bbox': [[103, 54, 547, 589]],\n",
              " 'class': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "val_annotations = read_json(VAL_ANNOTATIONS)\n",
        "val_annotations[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x-R2U0IDog2J"
      },
      "outputs": [],
      "source": [
        "def read(image_path, bboxes, label):\n",
        "    image = cv.imread(image_path)\n",
        "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "    image_h, image_w = image.shape[0:2]\n",
        "    image = cv.resize(image, (448, 448))\n",
        "    image = image / 255.\n",
        "\n",
        "    label_matrix = np.zeros([S, S, B*5+C])\n",
        "    for bbox in bboxes:\n",
        "        x, y, w, h = bbox\n",
        "\n",
        "        x = x / image_w\n",
        "        y = y / image_h\n",
        "        w = w / image_w\n",
        "        h = h / image_h\n",
        "\n",
        "        loc = [S * x, S * y]\n",
        "        loc_i = int(loc[1])\n",
        "        loc_j = int(loc[0])\n",
        "        y = loc[1] - loc_i\n",
        "        x = loc[0] - loc_j\n",
        "\n",
        "        if label_matrix[loc_i, loc_j, 4] == 0:\n",
        "            label_matrix[loc_i, loc_j, B*5+label] = 1\n",
        "            label_matrix[loc_i, loc_j, :4] = [x, y, w, h]\n",
        "            label_matrix[loc_i, loc_j, 4] = 1  # response\n",
        "\n",
        "    return image, label_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JWXLthl9og2K"
      },
      "outputs": [],
      "source": [
        "class YoloDataset(tf.keras.utils.Sequence) :\n",
        "\n",
        "    def __init__(self, annotations, batch_size, data_dir) :\n",
        "        self.annotations = annotations\n",
        "        self.batch_size = batch_size\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "    def __len__(self) :\n",
        "        return (np.ceil(len(self.annotations) / float(self.batch_size))).astype(np.int32)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx) :\n",
        "        batch = self.annotations[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "\n",
        "        train_image = []\n",
        "        train_label = []\n",
        "\n",
        "        for i in range(0, len(batch)):\n",
        "            img_path = batch[i]['image_path']\n",
        "            bboxes = batch[i]['bbox']\n",
        "            label = batch[i]['class']\n",
        "            image, label_matrix = read(os.path.join(self.data_dir, img_path), bboxes, label)\n",
        "            train_image.append(image)\n",
        "            train_label.append(label_matrix)\n",
        "\n",
        "        return np.array(train_image), np.array(train_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Tp4BRQnyog2K"
      },
      "outputs": [],
      "source": [
        "train_gen = YoloDataset(train_annotations, BATCH_SIZE, DATA_DIR)\n",
        "sample_image, sample_label = train_gen[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KQrBmxpcog2L"
      },
      "outputs": [],
      "source": [
        "val_gen = YoloDataset(val_annotations, BATCH_SIZE, DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nnhHjBGdog2L",
        "outputId": "bf805c6c-cecf-424f-b111-8cc6a831d836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 448, 448, 3) (4, 7, 7, 15)\n"
          ]
        }
      ],
      "source": [
        "print(sample_image.shape, sample_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VN73DZJlog2M"
      },
      "outputs": [],
      "source": [
        "class Yolo_Reshape(tf.keras.layers.Layer):\n",
        "  def __init__(self, target_shape):\n",
        "    super(Yolo_Reshape, self).__init__()\n",
        "    self.target_shape = tuple(target_shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'target_shape': self.target_shape\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  def call(self, input):\n",
        "    idx1 = S * S * B\n",
        "    idx2 = idx1 + S * S * C\n",
        "\n",
        "    # class probabilities\n",
        "    confs = K.reshape(input[:, :idx1], (K.shape(input)[0],) + tuple([S, S, B]))\n",
        "    confs = K.sigmoid(confs)\n",
        "\n",
        "    #confidence\n",
        "    class_probs = K.reshape(input[:, idx1:idx2], (K.shape(input)[0],) + tuple([S, S, C]))\n",
        "    class_probs = K.softmax(class_probs)\n",
        "\n",
        "    # boxes\n",
        "    boxes = K.reshape(input[:, idx2:], (K.shape(input)[0],) + tuple([S, S, B * 4]))\n",
        "    boxes = K.sigmoid(boxes)\n",
        "\n",
        "    outputs = K.concatenate([boxes, confs, class_probs])\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fgu6xBsgog2M"
      },
      "outputs": [],
      "source": [
        "def yolov1(img_h, img_w, s, b, c):\n",
        "    lrelu = tf.keras.layers.LeakyReLU(alpha=0.1)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=64, kernel_size= (7, 7), strides=(1, 1), input_shape =(img_h, img_w, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
        "\n",
        "    model.add(Conv2D(filters=192, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=256, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
        "\n",
        "    model.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=512, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
        "\n",
        "    model.add(Conv2D(filters=512, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=512, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=1024, kernel_size= (3, 3), strides=(2, 2), padding = 'same'))\n",
        "\n",
        "    model.add(Conv2D(filters=1024, kernel_size= (3, 3), activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "    model.add(Conv2D(filters=1024, kernel_size= (3, 3), activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(s*s*(b*5+c), activation='sigmoid'))\n",
        "    model.add(Yolo_Reshape(target_shape=(s, s, b*5+c)))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RYMsY77cog2M",
        "outputId": "649b77d2-6aae-41bb-8734-129562010162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 448, 448, 64)      9472      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 224, 224, 64)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 192)     110784    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 112, 112, 192)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 128)     24704     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 256)     295168    \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 112, 112, 256)     65792     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 112, 112, 512)     1180160   \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 56, 56, 512)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 256)       131328    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 56, 56, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 56, 56, 256)       131328    \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 56, 56, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 56, 56, 256)       131328    \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 56, 56, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 56, 56, 256)       131328    \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 56, 56, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 56, 56, 512)       262656    \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 56, 56, 1024)      4719616   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 28, 28, 1024)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 28, 28, 512)       524800    \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 28, 28, 1024)      4719616   \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 28, 28, 512)       524800    \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 28, 28, 1024)      4719616   \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 28, 28, 1024)      9438208   \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 14, 14, 1024)      9438208   \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 12, 12, 1024)      9438208   \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 10, 10, 1024)      9438208   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 102400)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               52429312  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 735)               753375    \n",
            "                                                                 \n",
            " yolo__reshape (Yolo_Reshap  (None, 7, 7, 15)          0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 113863967 (434.36 MB)\n",
            "Trainable params: 113863967 (434.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = yolov1(IMG_SIZE[0], IMG_SIZE[1], S, B, C)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7CIOkoO6og2M"
      },
      "outputs": [],
      "source": [
        "class CustomLearningRateScheduler(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, schedule):\n",
        "        super(CustomLearningRateScheduler, self).__init__()\n",
        "        self.schedule = schedule\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if not hasattr(self.model.optimizer, \"lr\"):\n",
        "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "        # Get the current learning rate from model's optimizer.\n",
        "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
        "        # Call schedule function to get the scheduled learning rate.\n",
        "        scheduled_lr = self.schedule(epoch, lr)\n",
        "        # Set the value back to the optimizer before this epoch starts\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
        "        print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, scheduled_lr))\n",
        "\n",
        "\n",
        "LR_SCHEDULE = [\n",
        "    # (epoch to start, learning rate) tuples\n",
        "    (0, 0.01),\n",
        "    (75, 0.001),\n",
        "    (105, 0.0001),\n",
        "]\n",
        "\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
        "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
        "        return lr\n",
        "    for i in range(len(LR_SCHEDULE)):\n",
        "        if epoch == LR_SCHEDULE[i][0]:\n",
        "            return LR_SCHEDULE[i][1]\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VVDAuDhZog2N"
      },
      "outputs": [],
      "source": [
        "def xywh2minmax(xy, wh):\n",
        "    xy_min = xy - wh / 2\n",
        "    xy_max = xy + wh / 2\n",
        "\n",
        "    return xy_min, xy_max\n",
        "\n",
        "\n",
        "def iou(pred_mins, pred_maxes, true_mins, true_maxes):\n",
        "    intersect_mins = K.maximum(pred_mins, true_mins)\n",
        "    intersect_maxes = K.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\n",
        "    pred_wh = pred_maxes - pred_mins\n",
        "    true_wh = true_maxes - true_mins\n",
        "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores = intersect_areas / union_areas\n",
        "\n",
        "    return iou_scores\n",
        "\n",
        "\n",
        "def yolo_head(feats):\n",
        "    # Dynamic implementation of conv dims for fully convolutional model.\n",
        "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
        "    # In YOLO the height index is the inner most iteration.\n",
        "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
        "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
        "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
        "\n",
        "    conv_width_index = K.tile(K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
        "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
        "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
        "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
        "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
        "\n",
        "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
        "\n",
        "    box_xy = (feats[..., :2] + conv_index) / conv_dims * IMG_SIZE[0]\n",
        "    box_wh = feats[..., 2:4] * 448\n",
        "\n",
        "    return box_xy, box_wh\n",
        "\n",
        "\n",
        "def yolo_loss(y_true, y_pred):\n",
        "    label_box = y_true[..., :4]  # ? * 7 * 7 * 4\n",
        "    response_mask = y_true[..., 4]  # ? * 7 * 7\n",
        "    response_mask = K.expand_dims(response_mask)  # ? * 7 * 7 * 1\n",
        "    label_class = y_true[..., B*5:B*5+C]  # ? * 7 * 7 * 20\n",
        "\n",
        "    predict_box = y_pred[..., :B*4]  # ? * 7 * 7 * 8\n",
        "    predict_trust = y_pred[..., B*4:B*4+2]  # ? * 7 * 7 * 2\n",
        "    predict_class = y_pred[..., B*4+2:B*4+2+C]  # ? * 7 * 7 * 20\n",
        "\n",
        "    _label_box = K.reshape(label_box, [-1, 7, 7, 1, 4])\n",
        "    _predict_box = K.reshape(predict_box, [-1, 7, 7, 2, 4])\n",
        "\n",
        "    label_xy, label_wh = yolo_head(_label_box)  # ? * 7 * 7 * 1 * 2, ? * 7 * 7 * 1 * 2\n",
        "    label_xy = K.expand_dims(label_xy, 3)  # ? * 7 * 7 * 1 * 1 * 2\n",
        "    label_wh = K.expand_dims(label_wh, 3)  # ? * 7 * 7 * 1 * 1 * 2\n",
        "    label_xy_min, label_xy_max = xywh2minmax(label_xy, label_wh)  # ? * 7 * 7 * 1 * 1 * 2, ? * 7 * 7 * 1 * 1 * 2\n",
        "\n",
        "    predict_xy, predict_wh = yolo_head(_predict_box)  # ? * 7 * 7 * 2 * 2, ? * 7 * 7 * 2 * 2\n",
        "    predict_xy = K.expand_dims(predict_xy, 4)  # ? * 7 * 7 * 2 * 1 * 2\n",
        "    predict_wh = K.expand_dims(predict_wh, 4)  # ? * 7 * 7 * 2 * 1 * 2\n",
        "    predict_xy_min, predict_xy_max = xywh2minmax(predict_xy, predict_wh)  # ? * 7 * 7 * 2 * 1 * 2, ? * 7 * 7 * 2 * 1 * 2\n",
        "\n",
        "    iou_scores = iou(predict_xy_min, predict_xy_max, label_xy_min, label_xy_max)  # ? * 7 * 7 * 2 * 1\n",
        "    best_ious = K.max(iou_scores, axis=4)  # ? * 7 * 7 * 2\n",
        "    best_box = K.max(best_ious, axis=3, keepdims=True)  # ? * 7 * 7 * 1\n",
        "\n",
        "    box_mask = K.cast(best_ious >= best_box, K.dtype(best_ious))  # ? * 7 * 7 * 2\n",
        "\n",
        "    no_object_loss = 0.5 * (1 - box_mask * response_mask) * K.square(0 - predict_trust)\n",
        "    object_loss = box_mask * response_mask * K.square(1 - predict_trust)\n",
        "    confidence_loss = no_object_loss + object_loss\n",
        "    confidence_loss = K.sum(confidence_loss)\n",
        "\n",
        "    class_loss = response_mask * K.square(label_class - predict_class)\n",
        "    class_loss = K.sum(class_loss)\n",
        "\n",
        "    _label_box = K.reshape(label_box, [-1, 7, 7, 1, 4])\n",
        "    _predict_box = K.reshape(predict_box, [-1, 7, 7, 2, 4])\n",
        "\n",
        "    label_xy, label_wh = yolo_head(_label_box)  # ? * 7 * 7 * 1 * 2, ? * 7 * 7 * 1 * 2\n",
        "    predict_xy, predict_wh = yolo_head(_predict_box)  # ? * 7 * 7 * 2 * 2, ? * 7 * 7 * 2 * 2\n",
        "\n",
        "    box_mask = K.expand_dims(box_mask)\n",
        "    response_mask = K.expand_dims(response_mask)\n",
        "\n",
        "    box_loss = 5 * box_mask * response_mask * K.square((label_xy - predict_xy) / 448)\n",
        "    box_loss += 5 * box_mask * response_mask * K.square((K.sqrt(label_wh) - K.sqrt(predict_wh)) / 448)\n",
        "    box_loss = K.sum(box_loss)\n",
        "\n",
        "    loss = confidence_loss + class_loss + box_loss\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YVcCQiwxog2N"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(MODEL_DIR):\n",
        "  os.makedirs(MODEL_DIR)\n",
        "\n",
        "mcp_save = ModelCheckpoint(os.path.join(MODEL_DIR, MODEL_WEIGHTS),\n",
        "                           save_best_only=True,\n",
        "                           monitor='val_loss',\n",
        "                           mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7oXn7N2zog2N"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=yolo_loss, optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zwz9B_umog2N",
        "outputId": "864f7769-77a3-4906-9f93-5d85d215a191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 00000: Learning rate is 0.0100.\n",
            "   6/2240 [..............................] - ETA: 14:34 - loss: 71.9926"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1565s vs `on_train_batch_end` time: 0.1946s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2240/2240 [==============================] - ETA: 0s - loss: 71.5423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2240/2240 [==============================] - 967s 416ms/step - loss: 71.5423 - val_loss: 58.4485\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e000394ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.fit(\n",
        "    x=train_gen,\n",
        "    steps_per_epoch=len(train_annotations)//BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=len(val_annotations)//BATCH_SIZE,\n",
        "    callbacks=[\n",
        "        CustomLearningRateScheduler(lr_schedule),\n",
        "        mcp_save\n",
        "    ]\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}